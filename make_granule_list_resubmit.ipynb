{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65abe5c-8550-4508-867e-3dd6bc46472a",
   "metadata": {},
   "source": [
    "# Make granule lists and submit files for held OSG Pool Jobs\n",
    "Takes as input a list generated by ```getheld.sh``` when running on a cluster on the OSG access point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef4073d-579d-4ee6-a824-8c63733c178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7a1f56-165f-4e72-bfb2-5edcb990bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_granule_list(input_list):\n",
    "    df = pd.read_csv(input_list, header=None, names=['fn','hold_reason'])\n",
    "    df['is_memory'] = df.apply(lambda x: 'exceeded request_memory' in x.hold_reason, axis=1)\n",
    "    df['granule'] = df.apply(lambda x: x.fn[x.fn.find('ATL03_'):x.fn.find('.h5')+3], axis=1)\n",
    "    def get_description(x):\n",
    "        substr = x.fn[x.fn.find('job_')+4:x.fn.find('_ATL03_')]\n",
    "        return substr[:substr.rfind('-')]\n",
    "    df['description'] = df.apply(get_description, axis=1)\n",
    "    def get_geojson(x):\n",
    "        parms = x.description.split('_')\n",
    "        parms[0] = 'ANT' if parms[0] == 'AIS' else 'GRE'\n",
    "        del parms[1]\n",
    "        return 'geojsons/simplified_' + '_'.join(parms) + '.geojson'\n",
    "    df['geojson'] = df.apply(get_geojson, axis=1)\n",
    "    df['geojson_full'] = df.apply(lambda x: x.geojson.replace('simplified_', ''), axis=1)\n",
    "    df = df[['granule','geojson','description','geojson_full','fn','hold_reason','is_memory']]\n",
    "    df.to_csv(input_list.replace('.csv', '_processed.csv'))\n",
    "    \n",
    "    df_mem = df[df.is_memory]\n",
    "    df_nomem = df[~df.is_memory]\n",
    "    \n",
    "    df_mem = df_mem.drop(columns=['fn','hold_reason','is_memory'])\n",
    "    df_nomem = df_nomem.drop(columns=['fn','hold_reason','is_memory'])\n",
    "    \n",
    "    fn_mem = input_list.replace('hold_lists/', 'granule_lists/').replace('final_', 'memory_')\n",
    "    fn_nomem = input_list.replace('hold_lists/', 'granule_lists/').replace('final_', 'resubmit_')\n",
    "    \n",
    "    df_mem.to_csv(fn_mem, header=False, index=False)\n",
    "    print('Wrote file %s. (%i jobs)' % (fn_mem, len(df_mem)))\n",
    "    df_nomem.to_csv(fn_nomem, header=False, index=False)\n",
    "    print('Wrote file %s. (%i jobs)' % (fn_nomem, len(df_nomem)))\n",
    "\n",
    "    return fn_mem, fn_nomem\n",
    "\n",
    "def write_submit_file(list_fn, sub_fn=None, mem_gb=16): \n",
    "    if not sub_fn:\n",
    "        sub_fn = list_fn.replace('granule_lists/', 'HTCondor_submit/').replace('.csv', '.submit')\n",
    "    \n",
    "    f = open(sub_fn, \"w\")\n",
    "    print('universe    = vanilla', file=f)\n",
    "    print('+SingularityImage = \"osdf:///ospool/ap21/data/fliphilipp/containers/icelake-container_v1.sif\"', file=f)\n",
    "    print('Requirements = HAS_SINGULARITY == True && OSG_HOST_KERNEL_VERSION >= 31000', file=f)\n",
    "    print('executable  = run_py.sh', file=f)\n",
    "    print('arguments = $(granule) $(polygon)', file=f)\n",
    "    print('max_retries = 30', file=f)\n",
    "    print('success_exit_code = 69', file=f)\n",
    "    print('transfer_input_files = detect_lakes.py, icelakes/__init__.py, icelakes/utilities.py, icelakes/nsidc.py, icelakes/detection.py, misc/test1, misc/test2, $(polygon), $(polygon_full)', file=f)\n",
    "    print('transfer_output_files = detection_out_data, detection_out_plot, detection_out_stat', file=f)\n",
    "    print('should_transfer_files = YES', file=f)\n",
    "    print('when_to_transfer_output = ON_EXIT', file=f)\n",
    "    print('log           = logs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).log', file=f)\n",
    "    print('error         = errs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).err', file=f)\n",
    "    print('output        = outs/job_$(descriptor)-$(ClusterID)_$(granule)-$(ProcID).out', file=f)\n",
    "    print('request_cpus    = 1', file=f)\n",
    "    print('request_memory  = %iGB' % mem_gb, file=f)\n",
    "    print('request_disk    = %iGB' % mem_gb, file=f)\n",
    "    print('queue granule,polygon,descriptor,polygon_full from %s' % list_fn, file=f)\n",
    "    f.close()\n",
    "    \n",
    "    print('Wrote file %s.\\n' % sub_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1d56b-4b93-435b-a967-d5f6fb5ee1eb",
   "metadata": {},
   "source": [
    "## Inital submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05722059-13db-4f37-9916-aa1544d00da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file HTCondor_submit/icelakes-methods.submit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_submit_file('granule_lists/icelakes-methods.csv', mem_gb=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icelakes-env",
   "language": "python",
   "name": "icelakes-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
